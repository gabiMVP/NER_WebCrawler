{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0116e63e93b64f858ceae4c01e0b3e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b759e6a2d9294ba0a7a3610374698aa8",
              "IPY_MODEL_79010133ba1e43c485a97814f6cb01e1",
              "IPY_MODEL_31ebde5d65d74e4dbb0ff94f160ba2ce"
            ],
            "layout": "IPY_MODEL_d2d4c7bcb07b4ea4b87b413e9e0810a8"
          }
        },
        "b759e6a2d9294ba0a7a3610374698aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be257f04770c43a7a9b7f145ecc37a4e",
            "placeholder": "​",
            "style": "IPY_MODEL_f7be518de66b4f80806118eca010a957",
            "value": "Map: 100%"
          }
        },
        "79010133ba1e43c485a97814f6cb01e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c4be595e6d24c209333c18d1203987e",
            "max": 796313,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e368e7e1975429da96bc0f13e0184cb",
            "value": 796313
          }
        },
        "31ebde5d65d74e4dbb0ff94f160ba2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce7f5036b4af408fb6ebedaee16228c6",
            "placeholder": "​",
            "style": "IPY_MODEL_68de2db0c933461280a17f2ab08383fb",
            "value": " 796313/796313 [00:55&lt;00:00, 27006.10 examples/s]"
          }
        },
        "d2d4c7bcb07b4ea4b87b413e9e0810a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be257f04770c43a7a9b7f145ecc37a4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7be518de66b4f80806118eca010a957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c4be595e6d24c209333c18d1203987e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e368e7e1975429da96bc0f13e0184cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ce7f5036b4af408fb6ebedaee16228c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68de2db0c933461280a17f2ab08383fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fd7fe5039fa7464485f0201accb2e30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_296482eca70e49eeb0de3c0ce2b54092",
              "IPY_MODEL_a19c5de79e64450f9e68b41afd1be575",
              "IPY_MODEL_cffc80ec15b542f9a7a7cf79daaefeda"
            ],
            "layout": "IPY_MODEL_de95e1a45c1e4faa84ff02be850f99db"
          }
        },
        "296482eca70e49eeb0de3c0ce2b54092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a547c67a076d43a19bdb7c850aaeaae1",
            "placeholder": "​",
            "style": "IPY_MODEL_3e8dfb04e0614558b7c5cdc41d0ca89a",
            "value": "Map: 100%"
          }
        },
        "a19c5de79e64450f9e68b41afd1be575": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddc0038bf4fd4882bdae9694a76dd78d",
            "max": 88480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c305580a04a439cadf0b6359fc89019",
            "value": 88480
          }
        },
        "cffc80ec15b542f9a7a7cf79daaefeda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d889cc9d461548299cc46588dc52dc2c",
            "placeholder": "​",
            "style": "IPY_MODEL_c4d1a2acef734956b4e85e756b91ce2c",
            "value": " 88480/88480 [00:03&lt;00:00, 25718.97 examples/s]"
          }
        },
        "de95e1a45c1e4faa84ff02be850f99db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a547c67a076d43a19bdb7c850aaeaae1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e8dfb04e0614558b7c5cdc41d0ca89a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddc0038bf4fd4882bdae9694a76dd78d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c305580a04a439cadf0b6359fc89019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d889cc9d461548299cc46588dc52dc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4d1a2acef734956b4e85e756b91ce2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__8V42JD62uu",
        "outputId": "cff0d1a1-3710-499a-d504-c337e99156ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu121)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers --quiet\n",
        "!pip install tokenizers --quiet\n",
        "!pip install datasets --quiet\n",
        "!pip install seqeval\n",
        "!pip install wget --quiet\n",
        "!pip install transformers[torch]\n",
        "import torch\n",
        "import wget\n",
        "import itertools\n",
        "import json\n",
        "import string\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from datasets import Dataset\n",
        "from datasets import load_metric\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "from ast import literal_eval\n",
        "import seqeval\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Since our target sites use SEO we can most likely infer they have robots.txt or sitemaps\n",
        "the best way to get the sitemap is from Robots.txt where there will be a link to it\n",
        "in the sitemap will be more links but some for sure will have all the product list, webshops do this for SEO\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "ROBOTS = '/robots.txt'\n",
        "Sitemaps = [\n",
        "    '/sitemap.xml',\n",
        "    '/sitemap-index.xml'\n",
        "    '/sitemap.php'\n",
        "    '/sitemap.txt'\n",
        "    '/sitemap.xml.gz'\n",
        "    '/sitemap/'\n",
        "    '/sitemap/sitemap.xml'\n",
        "    '/sitemapindex.xml'\n",
        "    '/sitemap/index.xml'\n",
        "    '/sitemap1.xml'\n",
        "]\n",
        "headers = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 14_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15'\n",
        "}\n",
        "# for seqEval library to work we must use the standard prefixes or else we get F1 score 1\n",
        "label_list = ['O', 'I-PRODUCT' , 'B-PRODUCT', 'E-PRODUCT']\n",
        "# always use the max label <nr of classes otherwise error at CrossEntropy\n",
        "label_encoding_dict = {'O': 0, 'I-PRODUCT': 1, 'B-PRODUCT': 2, 'E-PRODUCT': 3}\n",
        "\n",
        "task = \"ner\"\n",
        "model_checkpoint = \"xlm-roberta-base\"\n",
        "# model_checkpoint = \"xlm-roberta-large-finetuned-conll03-english\"\n",
        "batch_size = 64\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "metadata": {
        "id": "Djb6rA5v7tlp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22c9152c-f3d3-463b-cfd0-c7dcd7ed154a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper Functions"
      ],
      "metadata": {
        "id": "JxH40NZC_cKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def getInputOutputNotTokenized(xml, list_product_per_xml):\n",
        "    input = []\n",
        "    tags = []\n",
        "    xml_string = xml[0]\n",
        "    lines = xml_string.split('\\n')\n",
        "    # string_no_XML_tags  = BeautifulSoup(xml_string, \"xml\").getText()\n",
        "    # lines1 = string_no_XML_tags.split('\\n')\n",
        "    last_index = 0\n",
        "    product_len = len(list_product_per_xml) - 1\n",
        "    for i, text in enumerate(lines):\n",
        "        if last_index > product_len:\n",
        "            break\n",
        "        product = list_product_per_xml[last_index]\n",
        "        # this BeautifulSoup is there just to handle HTML entities because these can happen and the texts won't match\n",
        "        text1 = BeautifulSoup(text, \"xml\")\n",
        "        # we add a space before starting and closing tag so text split \" \" can split without removing the <>\n",
        "        text = text.replace(\"<\", \" <\")\n",
        "        text = text.replace(\">\", \"> \")\n",
        "        textList = text.split(\" \")\n",
        "        # remove empty space that be create by adding space\n",
        "        textList = [N for N in textList if N != \"\"]\n",
        "        if product in text or product in text1.getText():\n",
        "            last_index += 1\n",
        "            textToAdd = text1.getText().split(\" \")\n",
        "            # input.append(textToAdd)\n",
        "            idx_start = text.find(textToAdd[0])\n",
        "            idx_end = text.rfind(textToAdd[-1]) + len(textToAdd[-1])\n",
        "            string_before_target = \"\".join(text[0:idx_start])\n",
        "            string_after_target = \"\".join(text[idx_end:])\n",
        "            list_string_before_target = string_before_target.split(' ')\n",
        "            list_string_after_target = string_after_target.split(' ')\n",
        "            list_string_before_target = [N for N in list_string_before_target if N != \"\"]\n",
        "            list_string_after_target = [N for N in list_string_after_target if N != \"\"]\n",
        "            tags_beggining = ['O'] * len(list_string_before_target)\n",
        "            tags_end = ['O'] * len(list_string_after_target)\n",
        "            input.append(list_string_before_target + textToAdd + list_string_after_target)\n",
        "            # tags.append(['PRODUCT'] * len(textToAdd))\n",
        "            listProduct = ['I-PRODUCT'] * len(textToAdd)\n",
        "            listProduct[0] = 'B-PRODUCT'\n",
        "            listProduct[-1] = 'E-PRODUCT'\n",
        "            # tags.append(listProduct)\n",
        "            tags.append(tags_beggining + listProduct+tags_end)\n",
        "        else:\n",
        "            input.append(textList)\n",
        "            tags.append(['O'] * len(textList))\n",
        "    return input, tags\n",
        "\n",
        "\n",
        "\n",
        "def getTextAndProductsForSite(url):\n",
        "    try:\n",
        "        requests.get(url, headers=headers)\n",
        "    except:\n",
        "        print(\"site\" + url +\"is down\")\n",
        "        return\n",
        "    urlRobots = url + ROBOTS\n",
        "    r = requests.get(urlRobots, headers=headers)\n",
        "    m2 = BeautifulSoup(r.content, \"html.parser\")\n",
        "    listProp = m2.text.split('\\n')\n",
        "    sitemap = extractSiteMapfromRobotsTxt(listProp)\n",
        "    if '' == sitemap:\n",
        "        sitemap = tryKnownSitepath(url)\n",
        "        if '' == sitemap:\n",
        "            print(\"could not get data for site :\" + url)\n",
        "            # break for loop since we dont know the sitepath\n",
        "            return\n",
        "\n",
        "    r1 = requests.get(sitemap, headers=headers)\n",
        "    sitemapXml = BeautifulSoup(r1.content, \"xml\", from_encoding='utf-8')\n",
        "    # in sitemap we have links we go in one by one,  some of these will contain the products\n",
        "    listpaths = sitemapXml.findAll('loc')\n",
        "    stringsPage = []\n",
        "    products_page = []\n",
        "    dictList = []\n",
        "    for mainpath in listpaths:\n",
        "        r = requests.get(mainpath.text, headers=headers)\n",
        "        responsemainPage = BeautifulSoup(r.content, \"xml\")\n",
        "        x1 = responsemainPage.findAll(\"title\")\n",
        "        # string_page = [responsemainPage.getText()]\n",
        "        string_page = [str(responsemainPage)]\n",
        "        product_page = [str(x.getText()) for x in x1]\n",
        "        stringsPage.append(string_page)\n",
        "        products_page.append(product_page)\n",
        "        # dict ={\n",
        "        #     \"string_pageX\": string_page,\n",
        "        #     \"products_pageX\": product_page\n",
        "        # }\n",
        "        # dictList.append(dict)\n",
        "\n",
        "\n",
        "    if len(stringsPage) == 0 or len(products_page) ==0 :\n",
        "        return None\n",
        "    return {\n",
        "        \"string_page\": stringsPage,\n",
        "        \"products_page\": products_page,\n",
        "        # \"dict\":dictList\n",
        "    }\n",
        "\n",
        "\n",
        "def extractSiteMapfromRobotsTxt(listProp):\n",
        "    sitemap = ''\n",
        "    for line in listProp:\n",
        "        try:\n",
        "            l1 = line.split(' ')\n",
        "            if l1[0] == 'Sitemap:':\n",
        "                sitemap = l1[1]\n",
        "        except:\n",
        "            pass\n",
        "    if sitemap == \"\":\n",
        "        # use sitemap list\n",
        "        pass\n",
        "    return sitemap\n",
        "\n",
        "\n",
        "def getBasepage(link):\n",
        "    parsed = urlparse(link)\n",
        "    base = parsed.netloc\n",
        "    scheme = parsed.scheme\n",
        "    page = scheme + '://' + base\n",
        "    return page\n",
        "\n",
        "\n",
        "def tryKnownSitepath(url):\n",
        "    for sitePath in Sitemaps:\n",
        "        urltried = url + sitePath\n",
        "        r1 = requests.get(urltried)\n",
        "        if (r1.status_code == 200):\n",
        "            return urltried\n",
        "    return \"\"\n"
      ],
      "metadata": {
        "id": "FiMH84A1_k1a"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "esKHco2VCVv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#download site Data only if not provided already\n",
        "data_already_downloaded = True\n",
        "if not data_already_downloaded:\n",
        "    df = pd.read_csv('./data/furniture stores pages.csv')\n",
        "    df = df.dropna()\n",
        "    df_base_URL = df['max(page)'].map(getBasepage)\n",
        "    df_base_URL_np = df_base_URL.values\n",
        "    datasetList = []\n",
        "    # download site data , XML and list of product for each site and put in list\n",
        "    for i in range(10):\n",
        "        url = df_base_URL_np[i]\n",
        "        siteData = getTextAndProductsForSite(url)\n",
        "        datasetList.append(siteData)\n",
        "    # remove None elements which correspond to sites that give connection exception\n",
        "    datasetListCleanNone = [i for i in datasetList if i is not None]\n",
        "    # save data as JSON\n",
        "    with open(\"datasetRaw1.json\", \"w\") as outfile:\n",
        "        json.dump(datasetListCleanNone, outfile)\n",
        "#preprocess to Input Output form only if not already done or new data\n",
        "data_already_preprocessed = True\n",
        "if not data_already_preprocessed:\n",
        "    with open('datasetRaw1.json') as user_file:\n",
        "        parsed_json = json.load(user_file)\n",
        "    inputs, tags = [], []\n",
        "    # from the downloaded data pre process in Input Output form\n",
        "    for siteDict in parsed_json:\n",
        "        list_xmls = siteDict['string_page']\n",
        "        list_product_per_xml = siteDict['products_page']\n",
        "        lenght = len(list_xmls)\n",
        "        for i in range(lenght):\n",
        "            current_xml = list_xmls[i]\n",
        "            current_product_found = list_product_per_xml[i]\n",
        "            input, tag = getInputOutputNotTokenized(current_xml, current_product_found)\n",
        "            inputs.extend(input)\n",
        "            tags.extend(tag)\n",
        "    # save data to CVS\n",
        "    trainDF = pd.DataFrame({'tokens': inputs, 'ner_tags': tags})\n",
        "    trainDF.to_csv('data10Sites.csv', index=False, encoding='utf-8')\n",
        "\n",
        "#load cvs with data already prepared for Colab\n",
        "# driveLink = \"https://drive.google.com/uc?export=download&id=1Kf3gSu7F1Yfsra5adQrmvO7r7LyDnLg6\"\n",
        "driveLink = \"https://drive.google.com/uc?export=download&id=1M80WJAxwHojpheBxKOM9QMu2ULXDZY6q\"\n",
        "data_dir = './data'\n",
        "\n",
        "dataAlreadyExists = os.path.exists(data_dir)\n",
        "if not dataAlreadyExists:\n",
        "  os.makedirs(data_dir)\n",
        "  file_name = wget.download(driveLink,out = data_dir)\n",
        "trainDF =pd.read_csv('./data/data100SitesNEW_trunc.csv', encoding='utf-8')\n",
        "# we use literal_eval because when the CVS is saved list of strings becomes String in each entry\n",
        "trainDF['tokens'] = trainDF['tokens'].apply(literal_eval)\n",
        "trainDF['ner_tags'] = trainDF['ner_tags'].apply(literal_eval)\n",
        "\n",
        "dfSize = trainDF.shape[0]\n",
        "trainSize = dfSize * 0.90\n",
        "trainSize = int(trainSize)\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    label_all_tokens = True\n",
        "    tokenized_inputs = tokenizer(list(examples[\"tokens\"]), truncation=True, is_split_into_words=True)\n",
        "\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif label[word_idx] == '0':\n",
        "                label_ids.append(0)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]])\n",
        "            else:\n",
        "                label_ids.append(label_encoding_dict[label[word_idx]] if label_all_tokens else -100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "\n",
        "df_train = trainDF.iloc[:trainSize, :]\n",
        "df_test = trainDF.iloc[trainSize:, :]\n",
        "assert(df_test.shape[0] + df_train.shape[0] == dfSize)\n",
        "train_dataset = Dataset.from_pandas(df_train)\n",
        "test_dataset = Dataset.from_pandas(df_test)\n",
        "train_tokenized_datasets = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "test_tokenized_datasets = test_dataset.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0116e63e93b64f858ceae4c01e0b3e1a",
            "b759e6a2d9294ba0a7a3610374698aa8",
            "79010133ba1e43c485a97814f6cb01e1",
            "31ebde5d65d74e4dbb0ff94f160ba2ce",
            "d2d4c7bcb07b4ea4b87b413e9e0810a8",
            "be257f04770c43a7a9b7f145ecc37a4e",
            "f7be518de66b4f80806118eca010a957",
            "7c4be595e6d24c209333c18d1203987e",
            "4e368e7e1975429da96bc0f13e0184cb",
            "ce7f5036b4af408fb6ebedaee16228c6",
            "68de2db0c933461280a17f2ab08383fb",
            "fd7fe5039fa7464485f0201accb2e30a",
            "296482eca70e49eeb0de3c0ce2b54092",
            "a19c5de79e64450f9e68b41afd1be575",
            "cffc80ec15b542f9a7a7cf79daaefeda",
            "de95e1a45c1e4faa84ff02be850f99db",
            "a547c67a076d43a19bdb7c850aaeaae1",
            "3e8dfb04e0614558b7c5cdc41d0ca89a",
            "ddc0038bf4fd4882bdae9694a76dd78d",
            "4c305580a04a439cadf0b6359fc89019",
            "d889cc9d461548299cc46588dc52dc2c",
            "c4d1a2acef734956b4e85e756b91ce2c"
          ]
        },
        "id": "jhKZU-EoDu93",
        "outputId": "55ea6491-d70d-43ba-96f4-8c7748ffffde"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/796313 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0116e63e93b64f858ceae4c01e0b3e1a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/88480 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd7fe5039fa7464485f0201accb2e30a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data which is O example\n",
        "print(df_train.loc[[0]])\n",
        "print(train_tokenized_datasets[0])\n",
        "print(train_tokenized_datasets[0]['ner_tags'])\n",
        "print(train_tokenized_datasets[0]['labels'])\n",
        "# data which is Product  example\n",
        "print(df_train.loc[[22]])\n",
        "print(train_tokenized_datasets[22])\n",
        "print(train_tokenized_datasets[22]['ner_tags'])\n",
        "print(train_tokenized_datasets[22]['labels'])\n",
        "print(train_tokenized_datasets[22]['input_ids'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ42KZoE2bOG",
        "outputId": "8f326e90-ba81-4c1c-b768-c247a041952f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       tokens   ner_tags\n",
            "0  [<?xml, version=\"1.0\", encoding=\"utf-8\"?>]  [O, O, O]\n",
            "{'tokens': ['<?xml', 'version=\"1.0\"', 'encoding=\"utf-8\"?>'], 'ner_tags': ['O', 'O', 'O'], 'input_ids': [0, 4426, 32, 131492, 11389, 22422, 102107, 58, 22, 587, 6238, 22422, 1003, 420, 17376, 38843, 2740, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]}\n",
            "['O', 'O', 'O']\n",
            "[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]\n",
            "                                               tokens  \\\n",
            "22  [<image:title>, Fabric, Rocking, Armchair, wit...   \n",
            "\n",
            "                                             ner_tags  \n",
            "22  [O, B-PRODUCT, I-PRODUCT, I-PRODUCT, I-PRODUCT...  \n",
            "{'tokens': ['<image:title>', 'Fabric', 'Rocking', 'Armchair', 'with', 'Adjustable', 'Footrest', '-', 'Black', '</image:title>'], 'ner_tags': ['O', 'B-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'O'], 'input_ids': [0, 4426, 37926, 12, 5440, 2740, 3036, 73720, 14434, 214, 33119, 100983, 678, 3145, 20314, 2886, 159020, 56644, 20, 10074, 6, 42946, 37926, 12, 5440, 2740, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 0, 0, 0, -100]}\n",
            "['O', 'B-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'O']\n",
            "[-100, 0, 0, 0, 0, 0, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 0, 0, 0, 0, 0, 0, -100]\n",
            "[0, 4426, 37926, 12, 5440, 2740, 3036, 73720, 14434, 214, 33119, 100983, 678, 3145, 20314, 2886, 159020, 56644, 20, 10074, 6, 42946, 37926, 12, 5440, 2740, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "v9CPxrTA1LAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id2label = {\n",
        "    0: \"O\",\n",
        "    1: \"I-PRODUCT\",\n",
        "    2:'B-PRODUCT',\n",
        "    3:'E-PRODUCT'\n",
        "}\n",
        "label2id = {\n",
        "    \"O\": 0,\n",
        "    \"I-PRODUCT\": 1,\n",
        "    'B-PRODUCT': 2,\n",
        "    'E-PRODUCT': 3\n",
        "}\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_checkpoint, num_labels=len(label_list), ignore_mismatched_sizes=True,\n",
        "                                                        id2label=id2label, label2id=label2id)\n",
        "print(model)\n",
        "batch_size = 32\n",
        "args = TrainingArguments(\n",
        "    # torch_compile=True,\n",
        "    # fp16=True,\n",
        "    f\"test-{task}\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=2,\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer,max_length=128)\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [[label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in\n",
        "                        zip(predictions, labels)]\n",
        "    true_labels = [[label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in\n",
        "                   zip(predictions, labels)]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\"precision\": results[\"overall_precision\"], \"recall\": results[\"overall_recall\"],\n",
        "            \"f1\": results[\"overall_f1\"], \"accuracy\": results[\"overall_accuracy\"]}\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_tokenized_datasets,\n",
        "    eval_dataset=test_tokenized_datasets,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "trainer.evaluate()\n",
        "trainer.save_model('Roberta_NER.model')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YtiRkjp41SWh",
        "outputId": "80ea885d-d90f-4afd-92f1-87184d3dee69"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XLMRobertaForTokenClassification(\n",
            "  (roberta): XLMRobertaModel(\n",
            "    (embeddings): XLMRobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): XLMRobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-11): 12 x XLMRobertaLayer(\n",
            "          (attention): XLMRobertaAttention(\n",
            "            (self): XLMRobertaSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): XLMRobertaSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): XLMRobertaIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): XLMRobertaOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:752: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='49770' max='49770' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [49770/49770 1:37:14, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.012661</td>\n",
              "      <td>0.992290</td>\n",
              "      <td>0.981397</td>\n",
              "      <td>0.986813</td>\n",
              "      <td>0.999439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.012600</td>\n",
              "      <td>0.004301</td>\n",
              "      <td>0.987655</td>\n",
              "      <td>0.993092</td>\n",
              "      <td>0.990366</td>\n",
              "      <td>0.999418</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2765' max='2765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2765/2765 01:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "qD7Sx09DOxuc",
        "outputId": "fea9f78f-4ea0-4175-9a1e-4c284cc7534a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5530' max='2765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2765/2765 04:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.004300628788769245,\n",
              " 'eval_precision': 0.9876547408515848,\n",
              " 'eval_recall': 0.9930923639845433,\n",
              " 'eval_f1': 0.9903660886319846,\n",
              " 'eval_accuracy': 0.9994183163876565,\n",
              " 'eval_runtime': 134.7605,\n",
              " 'eval_samples_per_second': 656.572,\n",
              " 'eval_steps_per_second': 20.518,\n",
              " 'epoch': 2.0}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "saved_path =  '/content/Roberta_NER.model/'\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# model.save_pretrained('/content/Roberta_NER1.model')\n",
        "\n",
        "# !cp -r /content/Roberta_NER.model /content/drive/MyDrive/AiModels/Roberta_NER1.model\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_path, local_files_only=True)\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(saved_path)\n",
        "sample = df_test.iloc[15]\n",
        "sample_text = sample['tokens']\n",
        "sample_tags = sample['ner_tags']\n",
        "print(sample_text)\n",
        "print(sample_tags)\n",
        "sample_text = str(sample_text)\n",
        "tokens = tokenizer(sample_text)\n",
        "torch.tensor(tokens['input_ids']).unsqueeze(0).size()\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(saved_path,local_files_only=True, num_labels=len(label_list))\n",
        "predictions = model.forward(input_ids=torch.tensor(tokens['input_ids']).unsqueeze(0), attention_mask=torch.tensor(tokens['attention_mask']).unsqueeze(0))\n",
        "predictions = torch.argmax(predictions.logits.squeeze(), axis=1)\n",
        "print(predictions)\n",
        "predictions = [label_list[i] for i in predictions]\n",
        "print(predictions)\n",
        "\n",
        "words = tokenizer.batch_decode(tokens['input_ids'])\n",
        "x = pd.DataFrame({'ner': predictions, 'words': words}).to_csv('Roberta_base.csv')\n",
        "x = pd.DataFrame({'ner': predictions, 'words': words})\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IfwFDGChtYV",
        "outputId": "28c50620-0632-463d-bdbf-73dcfaa5a27b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<lastmod>', '2023-12-07T21:50:44+00:00', '</lastmod>']\n",
            "['O', 'O', 'O']\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0])\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "   ner   words\n",
            "0    O     <s>\n",
            "1    O       [\n",
            "2    O       '\n",
            "3    O       <\n",
            "4    O    last\n",
            "5    O     mod\n",
            "6    O       >\n",
            "7    O       '\n",
            "8    O       ,\n",
            "9    O       '\n",
            "10   O      20\n",
            "11   O      23\n",
            "12   O    -12-\n",
            "13   O      07\n",
            "14   O       T\n",
            "15   O      21\n",
            "16   O     :50\n",
            "17   O     :44\n",
            "18   O  +00:00\n",
            "19   O       '\n",
            "20   O       ,\n",
            "21   O       '\n",
            "22   O      </\n",
            "23   O    last\n",
            "24   O     mod\n",
            "25   O       >\n",
            "26   O       '\n",
            "27   O       ]\n",
            "28   O    </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test on eval data"
      ],
      "metadata": {
        "id": "uTesvyA94GdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = df_test.iloc[29]\n",
        "sample_text = sample['tokens']\n",
        "sample_tags = sample['ner_tags']\n",
        "print(str(sample_text))\n",
        "print(str(sample_tags))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tf-aS3od-o88",
        "outputId": "9efc0e4f-50b2-49d8-cb3e-9dff0fe937be"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<image:title>', 'Aeris', 'Occasional', 'Table', '</image:title>']\n",
            "['O', 'B-PRODUCT', 'I-PRODUCT', 'E-PRODUCT', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test on a never before seen site"
      ],
      "metadata": {
        "id": "PfxaQo-s4KvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pageTest = 'https://vauntdesign.com/'\n",
        "siteData = getTextAndProductsForSite(pageTest)\n",
        "print(siteData['string_page'][0])\n",
        "print(siteData['products_page'][0])\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_path)\n",
        "\n",
        "paragraph = str(BeautifulSoup(siteData['string_page'][0][0], \"xml\"))\n",
        "paragraph = paragraph[500:1024]\n",
        "print(\"paragraph:\" + paragraph)\n",
        "list_lines = paragraph.split(\"\\n\")\n",
        "tokens = tokenizer.batch_encode_plus(list_lines)\n",
        "dataFrame = pd.DataFrame()\n",
        "print(tokens)\n",
        "model = AutoModelForTokenClassification.from_pretrained(saved_path, num_labels=len(label_list))\n",
        "# since in training the model saw only line per line of the xml we have to preprocess and give it the input in the same format\n",
        "# with full paragraph the results are not as good\n",
        "for i, line in enumerate(tokens['input_ids']):\n",
        "    print(i)\n",
        "    print(line)\n",
        "    predictions = model.forward(input_ids=torch.tensor(tokens['input_ids'][i]).unsqueeze(0),\n",
        "                                attention_mask=torch.tensor(tokens['attention_mask'][i]).unsqueeze(0))\n",
        "    predictions = torch.argmax(predictions.logits.squeeze(), axis=1)\n",
        "    predictions = [label_list[i] for i in predictions]\n",
        "    words = tokenizer.batch_decode(tokens['input_ids'][i])\n",
        "    df1 = pd.DataFrame({'ner': predictions, 'words': words})\n",
        "    print(df1)\n",
        "    dataFrame = pd.concat([dataFrame, df1], axis=0)\n",
        "x = dataFrame.to_csv('Roberta.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRsjzM0sBLeb",
        "outputId": "c744495c-5797-4bce-d4ec-05338eaff2f4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<?xml version=\"1.0\" ....']\n",
            "['Firms Bedside Table', 'Bayon Salmon Pink Scatter Cushion', 'Sale Item 2', 'Sale Item 4 (old style Hege)', 'Sale Item 5', 'Sale Item 6', 'Sale Item 7', 'Sale Item 8', 'Bjarke Boucle Pouffe', 'Bjarke Grey Pouffe', 'Edvard Acacia Ribbed Sideboard', 'Edvard Acacia Ribbed Drinks Cabinet', 'Bjarke White Marble Coffee Table', 'Bjarke Black Marble Coffee Table', 'Bjarke White Marble Side Table', 'Bjarke Black Marble Side Table', 'Bjarke White Marble Console Table', 'Bjarke Black Marble Console Table', 'Solomon Jute Woven Day Bed', 'Solomon Jute Woven Day Bed Black', 'Cure Blue Leather Drawer Pull', 'Cure Black Leather Drawer Pull', 'Cure Pink Leather Drawer Pull', 'Cure Blue Leather Drawer Handle', 'Cure Black Leather Drawer Handle', 'Cure Pink Leather Drawer Handle', 'Idris Minimalist Glass Ball Chandeleir', 'Idris Glass Cluster Ceiling Light', 'Idris Frosted Glass Floor Lamp', 'Lane Bubble Table Lamp', 'Lane Black Sculptural Table Lamp', 'Idris Frosted Glass Wall Light', 'Idris Nordic Bar Wall Light', 'Disk Black Diffuser Wall Light', 'Disk Wall Light', 'Pill Waterproof Diffuser Wall Light', 'Pill Black Outdoor Wall Light', 'Xii Ribbed Table Lamp Blue', 'Xii Black Abstract Table Lamp', 'Kraft Black Velvet Pouffe', 'Kraft White Velvet Pouffe', 'Theodor Cane Bedside Table With Drawer', 'Theodor Mango Wood And Cane Bedside Table', 'Gunhild Marble Top Bedside Table', 'Gunhild Ribbed Oak Bedside Table', 'Henrick Art Deco Console Table, Marble and Black', 'Henrick Black Marble Console Table', 'Olavi Nordic Side Table', 'Olavi Black Marble Coffee Table', 'Olavi Black Marble Side Table', 'Edvard Acacia Ribbed TV Stand', 'Edvard Acacia Ribbed Chest Of Drawers', 'Dune Small Ceramic Vase', 'Ponda Wire Storage Basket', 'Agra Tall Ceramic Vase', 'Lodi Tall White Ceramic Vase Large', 'Char Wonky Blue Vase', 'Urdu Glass Box Planter Medium', 'Louis Copper Counter Stool', 'Arlo Brass Bar Stool, 75cm', 'Easton Leather Bar Stool', 'Arlo Gold Bar Stool', 'Arlo Pale Wood Bar Stool', 'Arlo Bar Stool Black Frame', 'Arlo Short Bar Stool', 'Stoker Counter Stool 65cm', 'Stoker Gold Counter Stool 65cm', 'Reggie Adjustable Leather Bar Stool', 'Louis Adjustable Bar Stool', 'Louis Gold Adjustable Bar Stool', 'Louis Black Swivel Bar Stool', 'Louis Adjustable Height Bar Stool', 'Stoker Black Counter Stool with Backrest 65cm', 'Stoker Light Wood Counter Stool With Backrest 65cm', 'Louis Adjustable Brass Bar Stool', 'Agonda Baskets Set of 3 Pink', 'Fearne Natural Seagrass Baskets, set of 3', 'Marta Handwoven Rattan Basket, Small', 'Marta Handwoven Rattan Basket, Large', 'Svea Small Seagrass basket With Lid', 'Yorick Fluted Bedside Table', 'Wine Rack 8 Glass', 'Wine Rack 18 Glass', 'Wine Rack 24 Glass', 'Jorne White Organic Candle Holder', 'Jorne Black Organic Candle Holder', 'Struktur White Candle Holder', 'Struktur Terracotta Orange Candle Holder', 'Struktur Beige Candle Holder', 'Struktur Black Candle Holder', 'Struktur White Textured Candle Holder', 'Struktur Beige Textured Candle Holder', 'Struktur Terracotta Orange Textured Candle Holder', 'Struktur Black Textured Candle Holder', 'Struktur White Designer Candle Holder', 'Struktur Beige Designer Candle Holder', 'Struktur Terracotta Orange Designer Candle Holder', 'Struktur Black Designer Candle Holder', 'Thora White Oval Candle Holder', 'Thora Beige Oval Candle Holder', 'Thora Terracotta Orange Oval Candle Holder', 'Thora Black Oval Candle Holder', 'Thora White Hoop Candle Holder', 'Thora Beige Hoop Candle Holder', 'Thora Terracotta Orange Hooped Candle Holder', 'Thora Black Hooped Candle Holder', 'Thora White Donut Candle Holder', 'Thora Beige Donut Candle Holder', 'Thora Terracotta Orange Donut Candle Holder', 'Thora Black Donut Candle Holder', 'Valkyrja Beige Multi Candle Holder, Hoops', 'Valkyrja Terracotta Orange Multi Candle Holder, Hoop', 'Valkyrja Black Multi Candle Holder, Hoop', 'Meja Green Marble Tealight Holder', 'Meja Pink Marble Candlestick Holder', 'Meja Pink Marble Candle Stand', 'Meja Pink Marble Tealight Holder', 'Meja Grey Marble Candle Stick Holder', 'Meja Grey Marble Candle Stand', 'Meja Green Marble Candle Stand', 'Meja Green Marble Candlestick Holder', 'Lena Dining Chairs Oak – set of 2', 'Lena Dining Chairs, Black – set of 2', 'Lena Dining Bench, Natural Oak', 'Lena Nordic Dining Bench, Black', 'Yorick Fluted Chest Of Drawers', 'Guise White Marble Wall Clock', 'Mono Concrete Wall Clock', 'Haakon Burnt Orange Organic Wall Clock', 'Haakon Black Organic Wall Clock', 'Trusk Moss Green Pendulum Table Clock', 'Trusk Latte Brown Pendulum Table Clock', 'Trusk Pastel Nude Table Clock, Pendulum', 'Trusk Matte Black Pendulum Desk Clock', 'Kindr Latte Brown Wall Clock', 'Kindr Moss Green Wall Clock', 'Jorey Green Pendulum Wall Clock, Contemporary', 'Jorey Black And Brass Pendulum Wall Clock, Contemporary', 'Kindr Nordic Wall Clock, Walnut', 'Kindr Walnut Brown Wall Clock', 'Kare White Designer Wall Clock, Pendulum', 'Kare Black Minimalist Wall Clock', 'Leif Moss Green Cuckoo Clock', 'Leif Matte Black Cuckoo Clock', 'Franklyn Metal Frame Coffee Table', 'Moxie Light Wood Coffee Table Parquet', 'Moxie Parquet Coffee Table', 'Hodi Concrete Coffee Table', 'Fika Large Coffee Table Black', 'Fika Large Oak Coffee Table Round', 'Fika Round Black Coffee Table', 'Lotus Round Brass Side Table', 'Fika Small Oak Coffee Table Round', 'Spectra Decorative Side Table', 'Lena Black Oak Coffee Table', 'Moxie Black Marble Coffee Table', 'Moxie White Marble Coffee Table', 'Luther Gold Coffee Table', 'Luther Pale Coffee Table', 'Baldr Ribbed Coffee Table', 'Olavi Marble Coffee Table', 'Baldr Black Coffee Table', 'Olavi Nordic Coffee Table', 'Hege Black Cane Console Table', 'Hege Rattan Console Table', 'Oxull Oak Console Table', 'Oxull Walnut Console Table', 'Gunhild Marble Console Table', 'Gunhild Oak Console Table', 'Olavi Wood And Marble Console Table', 'Olavi Black Ribbed Console Table', 'Baldr Black Half Moon Console Table', 'Baldr Wooden Half Moon Console Table', 'Mottle Wooden Cup Acacia', 'Awho Navy Blue Patterned Scatter Cushion', 'Bapu Charcoal Grey Scatter Cushion', 'Hazi Scatter Cushion Emerald Green', 'Hida Scatter Cushion Grey', 'Janata Geometric Cushion White', 'Januma Geometric Cushion Yellow', 'Maha Geometric Blue Scatter Cushion', 'Khatu Distressed Gold Cushion', 'Vasansi Scatter Cushion Plum Red', 'Whey Scatter Cushion, Green', 'Uller Bulrush Cushion, Blue', 'Uller Bulrush Cushion, Orange', 'Sion Geometric Cushion Purple', 'Sion Geometric Cushion, Orange', 'Tallus Vintage Floral Cushion', 'Sjakk Black And White Cushion', 'Sjakk Black And White Cushion Large', 'Sjakk Beige Rectangle Cushion', 'Sjakk Beige Cushion Large', 'Marrakesh Moroccan Coasters, Set of 6', 'Bo Short Wonky Bench', 'Bo Mango Wood Dining Bench', 'Baldr Ribbed Black Dining Bench', 'Baldr Long Black Bench Ribbed', 'Baldr Ribbed Dining Bench', 'Baldr Long Wooden Dining Bench', 'Baldr Ribbed Dining Table', 'Baldr Black Round Dining Table', 'Fell Cream velvet pouffe', 'Fell Scandi footstool', 'Fell Black velvet footstool', 'Arlo Copper Bar Stool', 'Arlo Metal Frame Bar Stool Gold', 'Arlo Wood and Metal Bar Stool', 'Arlo Wood and Metal Bar Stool Blue', 'Chester Metal Ladder Shelf Raw Metal', 'Chester Metal Ladder Shelf Black', 'Punji Industrial Open Shelving Unit', 'Sapa Round Wood and Metal Side Table, 50cm', 'Stoker Wooden Seat Bar Stool', 'Bray Hairpin Metal and Wood Dining Chair Black', 'Quoc Wooden Towel Ladder Black', 'Quoc Wooden Towel Ladder Green', 'Quoc Wooden Towel Ladder White', 'Bjarni Cream Cane Cabinet', 'Gift Cards £10', 'Gift Cards £25', 'Gift Cards £50', 'Gift Cards £100', 'Stockholm Stoneware Pitcher', 'Stockholm Stoneware Milk Jug', 'Jarl Glass coffee jar', 'Jarl Glass kitchen canister', 'Jarl Glass jar with cork lid', 'Jarl Glass Pasta Storage Jar', 'Jarl Green Glass Coffee Jar', 'Jarl Green Glass container', 'Jarl Glass storage jar', 'Jarl Large Glass container', 'Nordish Teak Ladder - 35cm', 'Nordish Teak Ladder - 50cm', 'Adde Black Towel Ladder', 'Hector Black Iron Lantern Large', 'Hector Black Iron lantern Medium', 'Anjuna Lantern Octagonal Large', 'Anjuna Lantern Octagonal Medium', 'Farzi Moroccan Bronze Lantern Large', 'Farzi Bronze Moroccan Lantern Medium', 'Coop Metal Cage Pendant Light', 'Etch Concrete Geometric Pendant', 'Loft Wood and Concrete Pendant', 'Outland Copper Ceiling Light', 'Mala Glass Jar Pendant Light Smoke', 'Jama Dome Pendant Light Large', 'Zelie Mesh Pendant Light', 'Jungli Wicker Lamp Shades Set of 3', 'Kiki Large Wicker Pendant Light Shade', 'Jahan Industrial Dome Pendant Light', 'Orla Glass Bell Jar Pendant Light', 'Hugo Bronze Pendant Light Medium', 'Adi Glass Pendant Light Shade', 'Geeta Industrial Table Lamp Green', 'Mala Glass Bell Jar Light Clear', 'Felix Concrete Table Lamp', 'Aubree Glass Cone Pendant Light', 'Jama Rustic Pendant Light Medium', 'Lennon Concrete Pendant', 'Gia Rope Ceiling Light', 'Havali Dome Ceiling Light', 'Harper Large Industrial Pendant Light', 'Cu Chi Bronze Lampshade Large', 'Franki Oversized Dome Pendant Light', 'Hugo Bronze Pendant Light Large', 'Nier Cage Pendant Light Black', 'Kerala Moroccan Pendant Oversized', 'Kochi Wicker Floor Lamp', 'Locky Industrial Tripod Floor Lamp', 'Cu Chi Bronze Lampshade Small', 'Locky Tripod Lamp Black and Bronze', 'Jungli Wicker Pendant Light', 'Berghain Concrete Pendant Light', 'Cu Chi Bronze Lampshade Medium', 'Faro Concrete Pendant Light', 'Portland Concrete Pendant Light', 'Denver Table Lamp Nickel', 'Canvas Black Wall Light Large', 'Kerala Moroccan Lamp Shade Large', 'Cu Chi Black Pendant Large', 'Cu Chi Black Industrial Pendant Medium', 'Ella Industrial Cage Pendant Medium', 'Dinsky Mesh Lampshade', 'Kerala Moroccan Pendant Small', 'Kerala Moroccan Lamp Shade Medium', 'Rica Basket Pendant Light', 'Odette Smoked Glass Pendant Small', 'Odette White Glass Pendant Light, Small', 'Braida Jute Lampshade Natural', 'Braida Jute Light Shade Black', 'Tuva Globe Glass Pendant Light, Large', 'Tuva Glass Pendant Light, Slim', 'Tuva Glass Pendant Light, Small', 'Tuva Frosted Pendant Light, Small', 'Épée Grey Cone Pendant Light', 'Épée Black Cone Pendant Light', 'Midgard Large Rattan Pendant Light Black', 'Astrid Paper Pendant Light, Large', 'Astrid Paper Pendant Light, Small', 'Unni Smoke Glass Pendant Light, Small', 'Unni Green Glass Pendant Light, Small', 'Kettil Wooden Milking Stool', 'Kettil Black Wooden Step Stool', 'Copenhagen Industrial Metal Mirror', 'Vapi Wall Mirror Small', 'Noida Gold Hanging Mirror', 'Lincoln Industrial Wall Mirror With Shelf', 'Polis Small Black Metal Mirror', 'Link Industrial Vanity Mirror', 'Elsie Gold Vanity Mirror', 'Oslo Oak Free Standing Mirror', 'Veil Tall Mirror With Shelf', 'Veil Landscape Mirror With Shelf', 'Laurel Rose Gold Mirror', 'Laurel Grey Geometric Mirror', 'Penington Wooden Dressing Table Mirror', 'Penington Black Dressing Table Mirror', 'Khaki Olive Wood Pestle and Mortar', 'Lint Concrete Storage Jars Set of 4', 'Lint Concrete Pink Storage Jar', 'Lint Concrete Navy Blue Storage Jar', 'Lint Concrete Grey Storage Jar', 'Umbel Concrete Vase', 'Boho Jute Basket White', 'Boho Chevron Jute Basket', 'Sima Concrete Planter Medium', 'Sima Concrete Pot Large', 'Agonda Baskets Set of 3 Dusty Blue', 'Ecru Concrete Succulent Pots Set of 3', 'Ecru Concrete Pot Large', 'Ecru Concrete Planter Medium', 'Agonda Baskets Set of 3 Green', 'Jasper Wire and Concrete Plant Pot', 'Ecru Concrete Planters Set of 3', 'Lodi Tall White Ceramic Vase Medium', 'Connaught Blue Ceramic Tankard', 'Loki Tall Wonky Glass Vase Large', 'Loki Tall Wonky Glass Vase Medium', 'Urdu Glass Box Planter Large', 'Agonda Baskets Set of 3 Grey', 'Agonda Baskets Set of 3 Natural', 'Forna Plant Stand Large', 'Forna Plant Stand Medium', 'Forna Plant Stand Small', 'Loco Natural Jute Pouffe White', 'Loco Natural Jute Pouffe Dark Grey', 'C.P. Turquoise Flat Weave Rug', 'Coral Black and White Geometric Rug', 'Veeru Moroccan Rug Blue', 'Bole Blue Mosaic Runner Rug', 'Mantle Grey Distressed Floor Runner', 'Ragori Blue Faded Rug', 'Soho Faded Vintage Area Rug Black', 'Brooklyn Grey Vintage Rug', 'Birla Navy Blue Geometric Rug', 'Juna Large Jute Rug', 'Juna Woven Jute Rug', 'Freja Rattan Screen', 'Seat Pad Black', 'Seat Pad Deep Tan', 'Seat Pad Rustic Tan', 'Seat Pad Ivory', 'Olea Olive Wood Salad Servers', 'Nook Minimalist Shelves', 'Melli Suspended Kitchen Shelf', 'Narla Hanging Wall Shelf', 'Melli Black Hanging Shelves', 'Nova Small Bedside Shelf', 'Nova Cream Bedside Shelf', 'Hodi Concrete Side Table', 'Skalep Charcoal Grey Side Table', 'Hodi Concrete Plinth', 'Triomphe Arched Side Table', 'Skalep Side Table Dusty Orange', 'Joris Cream Side Table', 'Skalep Charcoal Plinth', 'Skalep Terracotta Plinth', 'Lena Nordic Bedside Table', 'Lena Oak Bedside Table', 'Baldr Ribbed Side Table', 'Baldr Tall Pedestal Table', 'Olavi Marble Side Table', 'Baldr Black Side Table', 'Baldr Black Pedestal', 'Yorick Fluted Sideboard', 'Ilkeri Wall hooks, set of 4', 'Ilkeri Coat hook set', 'Ilkeri Marble hook set', 'Boe Hanging Kitchen Shelf, Small', 'Boe Ceiling Suspended Shelves, Medium', 'Boe Suspended Shelves, Large', 'Boe Suspended Bar Gantry, XL', 'Odin Black Industrial Table Lamp', 'Jord Stoneware Pitcher Natural Sand', 'Tuva White Glass Table Lamp', 'Tuva White Frosted Table Lamp', 'Ore Marble Pinch Pot', 'Ore & Dolo Pinch Pots', 'Bonn Rustic Serving Bowl Acacia', 'Lucca Wooden Serving Bowl', 'Lucca Wooden Serving Bowls', 'Malmo & Flam Tapas Board & Tray', 'Loess Marble and Wood Chopping Board', 'Dolo Wooden Pinch Pot', 'Flam Wooden Serving Board', 'Malmo Wooden Serving Tray Mango', 'Stockholm Hand Printed Soup Bowl', 'Stockholm Small Stoneware Bowl', 'Stockholm Succulent Planters Set of 3', 'Stockholm Stoneware Mug Striped', 'Stockholm Stoneware Plate Floral', 'Stockholm Stoneware Plate Striped', 'Stockholm Stoneware Bowls Set of 4', 'Stockholm Stoneware Bowls Set of 3', 'Musso Mini Wooden Pinch Pots', 'Karve Wooden Meze Bowls Set of 3', 'Loam Rustic Chopping Board Acacia', 'Kaolin Rustic Pizza Board Acacia', 'Alt Wooden Salt Spoon Acacia', 'Casa Wooden Tapas Board Acacia', 'Stockholm White Stoneware Teapot', 'Slät Wooden Plate Large', 'Slät Wooden Plate Medium', 'Wattle Spotted Cotton Napkin', 'Weft Stonewashed Placemat Charcoal', 'Weft Stonewashed Placemat Ash Grey', 'Weft Stonewashed Placemat Dusty Rose', 'Aska Stoneware Milk Jug Charcoal Grey', 'Aska Stoneware Pitcher Charcoal Grey', 'Aska Stoneware Bowl Charcoal Grey', 'Jord Stoneware Bowl Natural Sand', 'Jord Stoneware Milk Jug Natural Sand', 'Aska Stoneware Side Plate Charcoal Grey', 'Jord Stoneware Dinner Plate Natural Sand', 'Jord Stoneware Side Plate Natural Sand', 'Pallid Natural Jute Placemat', 'Imbue Black Placemat', 'Kale Natural Serving Board Medium', 'Weft Stonewashed Placemat Natural Sand', 'Aska Stoneware Mug Charcoal Grey', 'Aska Stoneware Plate Charcoal Grey', 'Jord Stoneware Mug Natural Sand', 'Wattle Spotted Cotton Tea Towel', 'Aska Dinnerware Set', 'Jord Dinnerware Set', 'Jord Stoneware Coffee Mugs Set', 'Aska Coffee Mugs Charcoal Set', 'Okken Aqua Tableware Set 16 Piece', 'Okken Blue Dinnerware Set 12 Piece', 'Okken Handleless Mug', 'Okken Stoneware Bowl', 'Okken Aqua Dinner Plate', 'Luleå Tableware Set 16 Piece', 'Luleå Dinnerware Set 12 Piece', 'Luleå Coffee Mugs Set of 4', 'Luleå Coffee Mug', 'Luleå Soup Bowls Set of 4', 'Luleå Speckled Side Plate', 'Luleå Speckled Dinner Plate', 'Luleå Speckled Bowl', 'Zeta Porcelain Dinner Set 12-Piece', 'Zeta Espresso Cup Set Specked White', 'Zeta Espresso Cup Set Black', 'Tasman Grey Marble Tray', 'Tasman Pink Marble Tray', 'Bambus Black Bamboo Placemat', 'Bambus Light Brown Bamboo Placemat', 'Bambus Dark Brown Bamboo Placemat', 'Bambus Bamboo Placemats', 'Hygge Wool Throw Blue', 'Forje Turkish Towel', 'Adana Turkish Throw Blue Large', 'Forje Wool Throw Navy and Mustard', 'Forje Wool Throw Olive Green', 'Forje Wool Throw Sea Blue', 'Forje Wool Throw Grey', 'Adana Turkish Throw Small', 'Rhine Distressed Throw Chocolate', 'Rhine Distressed Throw Green and Brown', 'Rhine Cotton Throw Grey', 'Metro Oversized Bed Throw Dusty Blue', 'Rhine Distressed Throw Dusty Red', 'Adana Turkish Throw Small Blue', 'Layla Cream Knitted Throw', 'Sloe Black Throw', 'Sjakk Beige Cotton Throw', 'Sjakk Black And White Cotton Throw', 'Kiruna Black And White Throw', 'Kiruna Beige Scandi Throw', 'Majken Beige Bedspread', 'Majken Black And White Bedspread', 'Hygge Wool Throw Duck Egg', 'Adana Turkish Throw', 'Adana Turkish Throw', 'Yorick Fluted TV Stand', 'Bhawan Tall Tribal Vase Large', 'Bhawan Tall Tribal Vase Medium', 'Flekk Straight Vase', 'Flekk Round Vase', 'Flekk Angular Vase, M', 'Flekk Angular Vase, L', 'Hjul Donut Vase', 'Kupol XS Vase', 'Kupol S Vase', 'Kupol M Vase', 'Kupol L Vase', 'Fagus Vase S', 'Fagus Vase L', 'Jorne White Minimalist Vase', 'Jorne Black Minimalist Vase', 'Jorne White Wonky Vase', 'Flute Green Organic Fluted Vase', 'Flute Green Rippled Glass Vase', 'Flute Smoked Organic Fluted Vase', 'Flute Smoked Rippled Glass Vase', 'Flute Burgundy Red Organic Fluted Glass Vase', 'Flute Burgundy Red Rippled Glass Vase', 'Rune Large Vase Sand', 'Rune Three Legged Vase', 'Rune Rough textured vase', 'Rune Sandy Textured Vase', 'Hinje Black flip clock', 'Hinje Retro flip clock', 'Canvas Bronze Wall Sconce Large', 'Esa Moroccan Wall Light Medium', 'Esa Moroccan Wall Light Large', 'Sigurd Black Wooden Shelf', 'Sigurd Extra Long Shelf']\n",
            "paragraph:mage:title>Firms Bedside Table</image:title>\n",
            "<image:caption/>\n",
            "</image:image>\n",
            "</url>\n",
            "<url>\n",
            "<loc>https://vauntdesign.com/products/bayon-salmon-pink-scatter-cushion</loc>\n",
            "<lastmod>2024-01-07T21:42:48+00:00</lastmod>\n",
            "<changefreq>daily</changefreq>\n",
            "<image:image>\n",
            "<image:loc>https://cdn.shopify.com/s/files/1/2001/3223/products/Salmonpinkcushion.jpg?v=1610199728</image:loc>\n",
            "<image:title>Bayon Salmon Pink Scatter Cushion</image:title>\n",
            "<image:caption>Salmon pink scatter cushion</image:caption>\n",
            "</image:image>\n",
            "</url>\n",
            "<url>\n",
            "<loc>ht\n",
            "{'input_ids': [[0, 1697, 13, 12, 5440, 2740, 6159, 42, 4432, 22417, 8752, 112997, 42946, 37926, 12, 5440, 2740, 2], [0, 4426, 37926, 12, 15644, 1363, 64, 2740, 2], [0, 6, 42946, 37926, 12, 37926, 2740, 2], [0, 6, 42946, 25002, 2740, 2], [0, 4426, 25002, 2740, 2], [0, 4426, 55043, 2740, 4397, 696, 330, 9109, 34198, 5, 277, 64, 57877, 7, 64, 14089, 191, 9, 2317, 3796, 9, 5128, 92, 9, 16275, 3055, 9, 1010, 3767, 191, 42946, 55043, 2740, 2], [0, 4426, 19777, 13415, 2740, 1549, 2357, 45669, 8368, 618, 3117, 33529, 34605, 238517, 42946, 19777, 13415, 2740, 2], [0, 4426, 152028, 12176, 864, 2740, 132338, 42946, 152028, 12176, 864, 2740, 2], [0, 4426, 37926, 12, 37926, 2740, 2], [0, 4426, 37926, 12, 55043, 2740, 4397, 696, 71574, 19, 5, 10534, 40383, 5, 277, 64, 7, 64, 29822, 7, 11583, 132542, 18113, 4015, 40061, 57877, 7, 64, 52779, 3796, 5128, 92, 1010, 3767, 191, 5, 25687, 32, 334, 1369, 2485, 963, 55589, 3882, 42946, 37926, 12, 55043, 2740, 2], [0, 4426, 37926, 12, 5440, 2740, 118978, 191, 6565, 3796, 59849, 81543, 3055, 3003, 3767, 191, 42946, 37926, 12, 5440, 2740, 2], [0, 4426, 37926, 12, 15644, 1363, 2740, 52779, 3796, 77233, 6, 16275, 3055, 314, 3767, 191, 42946, 37926, 12, 15644, 1363, 2740, 2], [0, 6, 42946, 37926, 12, 37926, 2740, 2], [0, 6, 42946, 25002, 2740, 2], [0, 4426, 25002, 2740, 2], [0, 4426, 55043, 2740, 9703, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}\n",
            "0\n",
            "[0, 1697, 13, 12, 5440, 2740, 6159, 42, 4432, 22417, 8752, 112997, 42946, 37926, 12, 5440, 2740, 2]\n",
            "          ner  words\n",
            "0           O    <s>\n",
            "1           O    mag\n",
            "2           O      e\n",
            "3           O      :\n",
            "4           O  title\n",
            "5           O      >\n",
            "6   B-PRODUCT     Fi\n",
            "7   B-PRODUCT      r\n",
            "8   B-PRODUCT     ms\n",
            "9   I-PRODUCT    Bed\n",
            "10  I-PRODUCT   side\n",
            "11  E-PRODUCT  Table\n",
            "12          O     </\n",
            "13          O  image\n",
            "14          O      :\n",
            "15          O  title\n",
            "16          O      >\n",
            "17          O   </s>\n",
            "1\n",
            "[0, 4426, 37926, 12, 15644, 1363, 64, 2740, 2]\n",
            "  ner  words\n",
            "0   O    <s>\n",
            "1   O      <\n",
            "2   O  image\n",
            "3   O      :\n",
            "4   O    cap\n",
            "5   O   tion\n",
            "6   O      /\n",
            "7   O      >\n",
            "8   O   </s>\n",
            "2\n",
            "[0, 6, 42946, 37926, 12, 37926, 2740, 2]\n",
            "  ner  words\n",
            "0   O    <s>\n",
            "1   O       \n",
            "2   O     </\n",
            "3   O  image\n",
            "4   O      :\n",
            "5   O  image\n",
            "6   O      >\n",
            "7   O   </s>\n",
            "3\n",
            "[0, 6, 42946, 25002, 2740, 2]\n",
            "  ner words\n",
            "0   O   <s>\n",
            "1   O      \n",
            "2   O    </\n",
            "3   O   url\n",
            "4   O     >\n",
            "5   O  </s>\n",
            "4\n",
            "[0, 4426, 25002, 2740, 2]\n",
            "  ner words\n",
            "0   O   <s>\n",
            "1   O     <\n",
            "2   O   url\n",
            "3   O     >\n",
            "4   O  </s>\n",
            "5\n",
            "[0, 4426, 55043, 2740, 4397, 696, 330, 9109, 34198, 5, 277, 64, 57877, 7, 64, 14089, 191, 9, 2317, 3796, 9, 5128, 92, 9, 16275, 3055, 9, 1010, 3767, 191, 42946, 55043, 2740, 2]\n",
            "   ner    words\n",
            "0    O      <s>\n",
            "1    O        <\n",
            "2    O      loc\n",
            "3    O        >\n",
            "4    O    https\n",
            "5    O      ://\n",
            "6    O       va\n",
            "7    O      unt\n",
            "8    O   design\n",
            "9    O        .\n",
            "10   O      com\n",
            "11   O        /\n",
            "12   O  product\n",
            "13   O        s\n",
            "14   O        /\n",
            "15   O      bay\n",
            "16   O       on\n",
            "17   O        -\n",
            "18   O      sal\n",
            "19   O      mon\n",
            "20   O        -\n",
            "21   O      pin\n",
            "22   O        k\n",
            "23   O        -\n",
            "24   O      sca\n",
            "25   O     tter\n",
            "26   O        -\n",
            "27   O       cu\n",
            "28   O      shi\n",
            "29   O       on\n",
            "30   O       </\n",
            "31   O      loc\n",
            "32   O        >\n",
            "33   O     </s>\n",
            "6\n",
            "[0, 4426, 19777, 13415, 2740, 1549, 2357, 45669, 8368, 618, 3117, 33529, 34605, 238517, 42946, 19777, 13415, 2740, 2]\n",
            "   ner   words\n",
            "0    O     <s>\n",
            "1    O       <\n",
            "2    O    last\n",
            "3    O     mod\n",
            "4    O       >\n",
            "5    O      20\n",
            "6    O      24\n",
            "7    O    -01-\n",
            "8    O      07\n",
            "9    O       T\n",
            "10   O      21\n",
            "11   O     :42\n",
            "12   O     :48\n",
            "13   O  +00:00\n",
            "14   O      </\n",
            "15   O    last\n",
            "16   O     mod\n",
            "17   O       >\n",
            "18   O    </s>\n",
            "7\n",
            "[0, 4426, 152028, 12176, 864, 2740, 132338, 42946, 152028, 12176, 864, 2740, 2]\n",
            "   ner   words\n",
            "0    O     <s>\n",
            "1    O       <\n",
            "2    O  change\n",
            "3    O     fre\n",
            "4    O       q\n",
            "5    O       >\n",
            "6    O   daily\n",
            "7    O      </\n",
            "8    O  change\n",
            "9    O     fre\n",
            "10   O       q\n",
            "11   O       >\n",
            "12   O    </s>\n",
            "8\n",
            "[0, 4426, 37926, 12, 37926, 2740, 2]\n",
            "  ner  words\n",
            "0   O    <s>\n",
            "1   O      <\n",
            "2   O  image\n",
            "3   O      :\n",
            "4   O  image\n",
            "5   O      >\n",
            "6   O   </s>\n",
            "9\n",
            "[0, 4426, 37926, 12, 55043, 2740, 4397, 696, 71574, 19, 5, 10534, 40383, 5, 277, 64, 7, 64, 29822, 7, 11583, 132542, 18113, 4015, 40061, 57877, 7, 64, 52779, 3796, 5128, 92, 1010, 3767, 191, 5, 25687, 32, 334, 1369, 2485, 963, 55589, 3882, 42946, 37926, 12, 55043, 2740, 2]\n",
            "   ner    words\n",
            "0    O      <s>\n",
            "1    O        <\n",
            "2    O    image\n",
            "3    O        :\n",
            "4    O      loc\n",
            "5    O        >\n",
            "6    O    https\n",
            "7    O      ://\n",
            "8    O       cd\n",
            "9    O        n\n",
            "10   O        .\n",
            "11   O     shop\n",
            "12   O      ify\n",
            "13   O        .\n",
            "14   O      com\n",
            "15   O        /\n",
            "16   O        s\n",
            "17   O        /\n",
            "18   O     file\n",
            "19   O        s\n",
            "20   O       /1\n",
            "21   O    /2001\n",
            "22   O       /3\n",
            "23   O       22\n",
            "24   O       3/\n",
            "25   O  product\n",
            "26   O        s\n",
            "27   O        /\n",
            "28   O      Sal\n",
            "29   O      mon\n",
            "30   O      pin\n",
            "31   O        k\n",
            "32   O       cu\n",
            "33   O      shi\n",
            "34   O       on\n",
            "35   O        .\n",
            "36   O      jpg\n",
            "37   O        ?\n",
            "38   O        v\n",
            "39   O        =\n",
            "40   O       16\n",
            "41   O       10\n",
            "42   O     1997\n",
            "43   O       28\n",
            "44   O       </\n",
            "45   O    image\n",
            "46   O        :\n",
            "47   O      loc\n",
            "48   O        >\n",
            "49   O     </s>\n",
            "10\n",
            "[0, 4426, 37926, 12, 5440, 2740, 118978, 191, 6565, 3796, 59849, 81543, 3055, 3003, 3767, 191, 42946, 37926, 12, 5440, 2740, 2]\n",
            "          ner  words\n",
            "0           O    <s>\n",
            "1           O      <\n",
            "2           O  image\n",
            "3           O      :\n",
            "4           O  title\n",
            "5           O      >\n",
            "6   B-PRODUCT    Bay\n",
            "7   B-PRODUCT     on\n",
            "8   I-PRODUCT    Sal\n",
            "9   I-PRODUCT    mon\n",
            "10  I-PRODUCT   Pink\n",
            "11  I-PRODUCT    Sca\n",
            "12  I-PRODUCT   tter\n",
            "13  E-PRODUCT     Cu\n",
            "14  E-PRODUCT    shi\n",
            "15  E-PRODUCT     on\n",
            "16          O     </\n",
            "17          O  image\n",
            "18          O      :\n",
            "19          O  title\n",
            "20          O      >\n",
            "21          O   </s>\n",
            "11\n",
            "[0, 4426, 37926, 12, 15644, 1363, 2740, 52779, 3796, 77233, 6, 16275, 3055, 314, 3767, 191, 42946, 37926, 12, 15644, 1363, 2740, 2]\n",
            "   ner  words\n",
            "0    O    <s>\n",
            "1    O      <\n",
            "2    O  image\n",
            "3    O      :\n",
            "4    O    cap\n",
            "5    O   tion\n",
            "6    O      >\n",
            "7    O    Sal\n",
            "8    O    mon\n",
            "9    O   pink\n",
            "10   O       \n",
            "11   O    sca\n",
            "12   O   tter\n",
            "13   O     cu\n",
            "14   O    shi\n",
            "15   O     on\n",
            "16   O     </\n",
            "17   O  image\n",
            "18   O      :\n",
            "19   O    cap\n",
            "20   O   tion\n",
            "21   O      >\n",
            "22   O   </s>\n",
            "12\n",
            "[0, 6, 42946, 37926, 12, 37926, 2740, 2]\n",
            "  ner  words\n",
            "0   O    <s>\n",
            "1   O       \n",
            "2   O     </\n",
            "3   O  image\n",
            "4   O      :\n",
            "5   O  image\n",
            "6   O      >\n",
            "7   O   </s>\n",
            "13\n",
            "[0, 6, 42946, 25002, 2740, 2]\n",
            "  ner words\n",
            "0   O   <s>\n",
            "1   O      \n",
            "2   O    </\n",
            "3   O   url\n",
            "4   O     >\n",
            "5   O  </s>\n",
            "14\n",
            "[0, 4426, 25002, 2740, 2]\n",
            "  ner words\n",
            "0   O   <s>\n",
            "1   O     <\n",
            "2   O   url\n",
            "3   O     >\n",
            "4   O  </s>\n",
            "15\n",
            "[0, 4426, 55043, 2740, 9703, 2]\n",
            "  ner words\n",
            "0   O   <s>\n",
            "1   O     <\n",
            "2   O   loc\n",
            "3   O     >\n",
            "4   O    ht\n",
            "5   O  </s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('NER_ROBERTA_XML_2.model')\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "!cp -r /content/NER_ROBERTA_XML_2.model /content/drive/MyDrive/InterviuNer/NER_ROBERTA_XML_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wutg-Mz6EuBD",
        "outputId": "7eafbd10-8d57-4263-d9b4-a2bcb59e4bd5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ]
}